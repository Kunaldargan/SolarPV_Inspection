{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "p0TzwomWgiY-",
    "outputId": "0d840195-ef77-4792-a7c5-50d39112c08d"
   },
   "outputs": [],
   "source": [
    "#!pip install opencv-python==3.4.2.16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "U1AliSurhHYl",
    "outputId": "0a007caa-eb3e-4445-a458-669152a82e52"
   },
   "outputs": [],
   "source": [
    "#!pip install opencv-contrib-python==3.4.2.16\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ipPBzfoahBu2"
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U7ohINuchBxr"
   },
   "outputs": [],
   "source": [
    "#checks if SIFT is working\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "print(sift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "u8IuUJWRiBRR",
    "outputId": "790acb81-f8b8-478b-b4b9-a2ba7b54507c"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modify function to extract result size of image and get the coordinates\n",
    "# Use the keypoints to stitch the images\n",
    "#grab image name alsso easier for writing\n",
    "def get_stitched_image(img1, img2, M):\n",
    "\n",
    "    # Get width and height of input images\n",
    "    w1,h1 = img1.shape[:2]\n",
    "    w2,h2 = img2.shape[:2]\n",
    "    \n",
    "    \n",
    "    # Get the canvas dimesions\n",
    "    img1_dims = np.float32([ [0,0], [0,w1], [h1, w1], [h1,0] ]).reshape(-1,1,2)\n",
    "    img2_dims_temp = np.float32([ [0,0], [0,w2], [h2, w2], [h2,0] ]).reshape(-1,1,2)\n",
    "\n",
    "\n",
    "    # Get relative perspective of second image\n",
    "    img2_dims = cv2.perspectiveTransform(img2_dims_temp, M)\n",
    "\n",
    "    # Resulting dimensions\n",
    "    result_dims = np.concatenate( (img1_dims, img2_dims), axis = 0)\n",
    "\n",
    "    # Getting images together\n",
    "    # Calculate dimensions of match points\n",
    "    [x_min, y_min] = np.int32(result_dims.min(axis=0).ravel() - 0.5)\n",
    "    [x_max, y_max] = np.int32(result_dims.max(axis=0).ravel() + 0.5)\n",
    "    \n",
    "\n",
    "    # Create output array after affine transformation \n",
    "    transform_dist = [-x_min,-y_min]\n",
    "    #show tha image \n",
    "    \n",
    "    #plt.imshow(img2)\n",
    "    transform_array = np.array([[1, 0, transform_dist[0]], \n",
    "                                [0, 1, transform_dist[1]], \n",
    "                                [0,0,1]]) \n",
    "\n",
    "    # Warp images to get the resulting image\n",
    "    result_img = cv2.warpPerspective(img2, transform_array.dot(M), \n",
    "                                    (x_max-x_min, y_max-y_min))\n",
    "    #Result_image1\n",
    "    #selective image region print \n",
    "    res1 = result_img[transform_dist[1]:w1+transform_dist[1],transform_dist[0]:h1+transform_dist[0]]\n",
    "    \n",
    "    \n",
    "    #image stitched final\n",
    "    result_img[transform_dist[1]:w1+transform_dist[1], \n",
    "                transform_dist[0]:h1+transform_dist[0]] = img1\n",
    "    \n",
    "\n",
    "\n",
    "    #extract image2 shape since it has been pasted on the canvas\n",
    "    w1,h1,_ = img2.shape\n",
    "    \n",
    "    #extract reusult image height and width for cropping\n",
    "    w2,h2,_ = result_img.shape\n",
    "    \n",
    "\n",
    "    print('Stitching Done')\n",
    "\n",
    "    \n",
    "    return result_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UbksLoAGkXBI"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Find SIFT and return Homography Matrix\n",
    "def get_sift_homography(img1, img2):\n",
    "     \n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    \n",
    "    # Extract keypoints and descriptors\n",
    "    k1, d1 = sift.detectAndCompute(img1, None)\n",
    "    k2, d2 = sift.detectAndCompute(img2, None)\n",
    "    if ( d1 is None or d2 is None):\n",
    "      print('Images are different')\n",
    "      print('Set of images from _ to ', image_name)\n",
    "      print(d1)\n",
    "      \n",
    "    else:\n",
    "\n",
    "      FLANN_INDEX_KDTREE = 0\n",
    "      index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "      search_params = dict(checks=50)   # or pass empty dictionary\n",
    "\n",
    "      flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "\n",
    "      matches = flann.knnMatch(d1,d2,k=2)\n",
    "\n",
    "\n",
    "      # Make sure that the matches are good\n",
    "      #verify_ratio = 0.6 # Source: stackoverflow\n",
    "      verified_matches = []\n",
    "      for m1,m2 in matches:\n",
    "          # Add to array only if it's a good match\n",
    "          if m1.distance < 0.85 * m2.distance:\n",
    "              verified_matches.append(m1)\n",
    "\n",
    "      # Mimnum number of matches\n",
    "      min_matches = 8\n",
    "      if len(verified_matches) > min_matches:\n",
    "\n",
    "          # Array to store matching points\n",
    "          img1_pts = []\n",
    "          img2_pts = []\n",
    "\n",
    "          # Add matching points to array\n",
    "          for match in verified_matches:\n",
    "              img1_pts.append(k1[match.queryIdx].pt)\n",
    "              img2_pts.append(k2[match.trainIdx].pt)\n",
    "          img1_pts = np.float32(img1_pts).reshape(-1,1,2)\n",
    "          img2_pts = np.float32(img2_pts).reshape(-1,1,2)\n",
    "\n",
    "          # Compute homography matrix\n",
    "          M, mask = cv2.findHomography(img1_pts, img2_pts, cv2.RANSAC, 5.0)\n",
    "          return M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u0gHy_ojkXDz"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Equalize Histogram of Color Images\n",
    "def equalize_histogram_color(img):\n",
    "    img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "    img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])\n",
    "    img = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize images before sending \n",
    "#res 640 x 480\n",
    "\n",
    "cv_img = []\n",
    "img_name_list = []\n",
    "\n",
    "#pick images from directory and add to a array. Extract filename from directory and add them to a list\n",
    "\n",
    "#files = [item for sublist in [glob.glob(path + ext) for ext in [\"/*.jpg\", \"/*.JPG\", \"/*.png\", \"/*.PNG\"]] for item in sublist]\n",
    "\n",
    "#print(files)\n",
    "output_path = '/home/sameer/Jupyter_Notebook/Demo_Data/Output_Stitched2/'\n",
    "\n",
    "dict_1 = {}\n",
    "\n",
    "#combined is masked images and Images contains original images \n",
    "pathname1 = '/home/sameer/Jupyter_Notebook/Demo_Data/Sorted_Images/'\n",
    "\n",
    "\n",
    "count = 0\n",
    "\n",
    "for item1 in sorted(os.listdir(pathname1)):    \n",
    "            if item1.endswith('.jpg'):\n",
    "            \n",
    "                path1 = os.path.join(pathname1,item1)\n",
    "\n",
    "                #path2 = os.path.join(pathname2,item1)\n",
    "                #read image 1 and 2\n",
    "                count = count +1\n",
    "\n",
    "                #read image 1 and 2\n",
    "                image1 = cv2.imread(path1)\n",
    "                cv_img.append(image1)\n",
    "                img_name_list.append(item1)\n",
    "                #print(item1)\n",
    "    \n",
    "img1 = cv_img[0]\n",
    "count1 = 0 \n",
    "previous_height = 0\n",
    "set_count = 1\n",
    "\n",
    "set_file_names = []\n",
    "for i in range(0,len(cv_img)):\n",
    "    \n",
    "    \n",
    "    img2= cv_img[i]\n",
    "    \n",
    "    \n",
    "    image_name = img_name_list[i]\n",
    "    img1 = equalize_histogram_color(img1)\n",
    "    img2 = equalize_histogram_color(img2)\n",
    "\n",
    "    M =  get_sift_homography(img1, img2)\n",
    "        \n",
    "\n",
    "    result_image = get_stitched_image(img2, img1, M)\n",
    "    \n",
    "    output_image = os.path.join(output_path, image_name)\n",
    "    \n",
    "    cv2.imwrite(output_image, result_image)\n",
    "    \n",
    "    img1=result_image\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy of Google_Colab_Overlap _Extract.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
